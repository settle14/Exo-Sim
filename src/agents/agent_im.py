# Copyright (c) 2025 Mathis Group for Computational Neuroscience and AI, EPFL
# All rights reserved.
#
# Licensed under the BSD 3-Clause License.
#
# This file contains code adapted from:
#
# 1. PHC_MJX (https://github.com/ZhengyiLuo/PHC_MJX)

import os
import torch
import numpy as np
import logging

os.environ["OMP_NUM_THREADS"] = "1"

from src.agents.agent_humanoid import AgentHumanoid
from src.learning.learning_utils import to_test, to_cpu
from src.env.myolegs_im import MyoLegsIm
from typing import Tuple
logger = logging.getLogger(__name__)


class AgentIM(AgentHumanoid):
    """
    AgentIM is a specialized reinforcement learning agent for humanoid environments,
    extending AgentHumanoid with specific functionalities for the MyoLegsIm environment.
    """
    
    def __init__(self, cfg, dtype, device, training: bool = True, checkpoint_epoch: int = 0):
        """
        Initialize the AgentIM with configurations and set up necessary components.

        Args:
            cfg: Configuration object containing hyperparameters and settings.
            dtype: Data type for tensors (e.g., torch.float32).
            device: Device for computations (e.g., 'cuda' or 'cpu').
            training (bool, optional): Flag indicating if the agent is in training mode.
            checkpoint_epoch (int, optional): Epoch number from which to load the checkpoint.
        """
        super().__init__(cfg, dtype, device, training, checkpoint_epoch)

    def get_full_state_weights(self) -> dict:
        """
        Extends the state dictionary with termination history for checkpointing.

        Returns:
            dict: The state dictionary including termination history.
        """
        state = super().get_full_state_weights()
        return state
    
    def set_full_state_weights(self, state) -> None:
        """
        Loads the state dictionary.

        Args:
            state (dict): The state dictionary including termination history.
        """
        super().set_full_state_weights(state)
        
    
    def pre_epoch(self) -> None:
        """
        Performs operations before each training epoch, such as resampling motions.
        """
        if (self.epoch > 1) and self.epoch % self.cfg.env.resampling_interval == 1: # + 1 to evade the evaluations. 
            self.env.sample_motions()
        return super().pre_epoch()
    
    def setup_env(self):
        """
        Initializes the MyoLegsIm environment based on the configuration.
        """
        self.env = MyoLegsIm(self.cfg)
        logger.info("MyoLegsIm environment initialized.")

    def eval_policy(self, epoch: int = 0, dump: bool = False, runs=None) -> float:
        """
        Evaluate current policy. If cfg.run.exo_eval_both == True, run AB tests:
        - exo_on  (å¤–éª¨éª¼åŠ›çŸ©æŒ‰ç­–ç•¥è¾“å‡º)
        - exo_off (å¤–éª¨éª¼åŠ›çŸ©ç½®é›¶)
        Prints success/MPJPE/coverage and energy-style metrics:
        human_energy, exo_energy, exo_smooth, assist_align(+ pos/neg)
        Also logs to wandb if available.
        """
        logger = logging.getLogger(__name__)
        logger.info("Starting policy evaluation.")
        # æ ‡è®°è¯„ä¼°æ¨¡å¼ï¼ˆç¯å¢ƒå†…éƒ¨å¯èƒ½ä¼šæ”¹å˜ç»ˆæ­¢/æ¸²æŸ“è¡Œä¸ºï¼‰
        self.env.start_eval(im_eval=True)

        def _one_pass(tag: str, exo_zero: bool):
            # è¯„ä¼°æœŸåˆ‡æ¢å¤–éª¨éª¼æ˜¯å¦ç½®é›¶ï¼ˆéœ€è¦ env.set_exo_zero å·²å®ç°ï¼‰
            if hasattr(self.env, "set_exo_zero"):
                self.env.set_exo_zero(exo_zero)
            # === æ–°å¢ï¼šAB åˆ‡æ¢å‰æ¸…ç† env é‡Œä¸ assist ç›¸å…³çš„ç¼“å­˜ ===
            # æ¸…å†å² jerk é˜Ÿåˆ—ï¼Œé¿å… r_as å—ä¸Šä¸€æ¬¡å½±å“
            if hasattr(self.env, "_exo_hist") and self.env._exo_hist is not None:
                try:
                    self.env._exo_hist.clear()
                except Exception:
                    pass
            # å°†ä¸Šä¸€æ—¶åˆ»å¤–éª¨éª¼åŠ›çŸ©æ¸…é›¶ï¼Œé¿å…ç¬¬ä¸€æ­¥ Î”u å¼‚å¸¸æ”¾å¤§
            if hasattr(self.env, "_exo_prev"):
                try:
                    import numpy as _np
                    self.env._exo_prev = _np.zeros_like(self.env._exo_prev)
                except Exception:
                    self.env._exo_prev = None
            # æ¸…ç©ºæœ¬ episode çš„ exo ç»Ÿè®¡é‡
            for _name in ("curr_exo_usage", "curr_exo_rate"):
                if hasattr(self.env, _name) and isinstance(getattr(self.env, _name), list):
                    getattr(self.env, _name).clear()
            # æ˜ç¡®æ ‡è®° exo_zero åˆ° envï¼ˆæœ‰äº› reward ä¼šè¯»å–è¯¥æ ‡è®°ï¼‰
            setattr(self.env, "_exo_zero", bool(exo_zero))

                        # ï¼ˆå¯é€‰ï¼‰å¥å£®æ€§æ‰“å°
            try:
                sdim = self.env.observation_space.shape[0]
                adim = self.env.action_space.shape[0]
                logger.debug(f"[{tag}] obs_dim={sdim}, act_dim={adim}, exo_zero={exo_zero}")
            except Exception:
                pass


            success_dict, mpjpe_dict, frame_coverage_dict = {}, {}, {}
            # New metric buffers that match myolegs_im.py reward_info
            rm_list, ras_list, rtau_list = [], [], []
            work_list, tausq_list = [], []
            upright_list, eh_list = [], []
            rbody_list, rrootxy_list = [], []


            # ç”¨ç¡®å®šæ€§åŠ¨ä½œè¯„ä¼°ï¼›to_cpu åˆ‡å› CPUï¼Œé¿å…å¤š GPU ç¯å¢ƒçš„èµ„æºå ç”¨
            with to_cpu(*self.sample_modules), torch.no_grad():
                # ä¿å®ˆï¼šç¡®ä¿ç­–ç•¥å¤„äº eval æ¨¡å¼
                try:
                    self.policy_net.eval()
                except Exception:
                    pass

                for run_idx in self.env.forward_motions():
                    # å•çº¿ç¨‹è¯„ä¼°æ¥å£
                    result, mpjpe, frame_coverage = self.eval_single_thread()

                    # Pull new reward_info fields written in myolegs_im.py
                    # r_m, r_as, r_tau are already squashed in [0,1] form (exp(-sigma * cost))
                    info = getattr(self.env, "reward_info", {}) or {}
                    if "r_m" in info:
                        rm_list.append(float(info["r_m"]))
                    if "r_as" in info:
                        ras_list.append(float(info["r_as"]))
                    if "r_tau" in info:
                        rtau_list.append(float(info["r_tau"]))
                    if "work_val_proxy" in info:
                        work_list.append(float(info["work_val_proxy"]))
                    if "tau_sq" in info:
                        tausq_list.append(float(info["tau_sq"]))
                    if "upright_reward" in info:
                        upright_list.append(float(info["upright_reward"]))
                    if "energy_human" in info:
                        eh_list.append(float(info["energy_human"]))
                    if "r_body_pos" in info:
                        rbody_list.append(float(info["r_body_pos"]))
                    


                    success_dict[run_idx] = bool(result)
                    mpjpe_dict[run_idx] = float(mpjpe)
                    frame_coverage_dict[run_idx] = float(frame_coverage)

                    if runs is not None and len(success_dict) >= int(runs):
                        break

            # æ±‡æ€»
            srate = np.mean(list(success_dict.values())) if success_dict else 0.0
            mpjpe_mean = np.mean(list(mpjpe_dict.values())) if mpjpe_dict else 0.0
            cov_mean = np.mean(list(frame_coverage_dict.values())) if frame_coverage_dict else 0.0
            rm_mean    = np.mean(rm_list)    if rm_list    else 0.0
            ras_mean   = np.mean(ras_list)   if ras_list   else 0.0
            rtau_mean  = np.mean(rtau_list)  if rtau_list  else 0.0
            work_mean  = np.mean(work_list)  if work_list  else 0.0
            tausq_mean = np.mean(tausq_list) if tausq_list else 0.0
            upr_mean   = np.mean(upright_list) if upright_list else 0.0
            eh_mean    = np.mean(eh_list)    if eh_list    else 0.0
            rbody_mean  = np.mean(rbody_list)  if rbody_list  else 0.0
            


            # æ‰“å°ï¼ˆmpjpe -> æ¯«ç±³ï¼‰
            print(
                f"[{tag}] success={srate*100:.2f}%, MPJPE={mpjpe_mean*1000:.3f}mm, "
                f"coverage={cov_mean*100:.2f}%"
            )
            print(
                f"[{tag}] r_m~{rm_mean:.3f}, r_as~{ras_mean:.3f}, r_tau~{rtau_mean:.3f}, "
                f"work_proxy~{work_mean:.4f}, tau_sq~{tausq_mean:.4f}, "
                f"human_energy~{eh_mean:.4f}, upright~{upr_mean:.3f}, "
                f"r_body_pos~{rbody_mean:.3f}"
            )



            # å¯é€‰ï¼šwandb è®°å½•ï¼ˆè‹¥æœªåˆå§‹åŒ–æˆ–æ—  wandbï¼Œä¸æŠ¥é”™ï¼‰
            try:
                import wandb  # noqa: F401
                wandb.log(
                    {
                        f"{tag}/success": srate,
                        f"{tag}/mpjpe_mm": mpjpe_mean * 1000.0,
                        f"{tag}/coverage": cov_mean,
                        f"{tag}/r_m": rm_mean,
                        f"{tag}/r_as": ras_mean,
                        f"{tag}/r_tau": rtau_mean,
                        f"{tag}/work_proxy": work_mean,
                        f"{tag}/tau_sq": tausq_mean,
                        f"{tag}/human_energy": eh_mean,
                        f"{tag}/upright": upr_mean,
                        f"{tag}/r_body_pos": rbody_mean,
                        

                    },
                    step=getattr(self, "epoch", epoch),
                )

            except Exception:
                pass

            return mpjpe_dict

        # AB å¯¹ç…§ï¼ˆé»˜è®¤è¯»å– cfg.run.exo_eval_bothï¼›è‹¥ä¸º Falseï¼Œåªè·‘ exo_onï¼‰
        if getattr(self.cfg.run, "exo_eval_both", False):
            dict_on = _one_pass("exo_on", exo_zero=False)
            dict_off = _one_pass("exo_off", exo_zero=True)
            return dict_on, dict_off
        else:
            # è‹¥ç”¨æˆ·é€šè¿‡ cfg.run.exo_zero æŒ‡å®šå•æ¬¡å–å€¼ï¼Œåˆ™å°Šé‡è¯¥å¼€å…³
            exo_zero_flag = bool(getattr(self.cfg.run, "exo_zero", False))
            tag = "exo_off" if exo_zero_flag else "exo_on"
            result = _one_pass(tag, exo_zero=exo_zero_flag)
            return result, (np.mean(list(result.values())) if result else 0.0)




    
    def eval_single_thread(self) -> Tuple[bool, float, float]:
        """
        Evaluates the policy in a single thread by running an episode.

        Returns:
            Tuple[bool, float, float]: (success_flag, mpjpe_value, frame_coverage)
        """
        with to_cpu(*self.sample_modules), torch.no_grad():
            obs_dict, info = self.env.reset()
            state = self.preprocess_obs(obs_dict)
            for t in range(10000):
                actions = self.policy_net.select_action(
                    torch.from_numpy(state).to(self.dtype), True
                )[0].numpy()
                next_obs, reward, terminated, truncated, info = self.env.step(
                    self.preprocess_actions(actions)
                )
                next_state = self.preprocess_obs(next_obs)
                done = terminated or truncated

                if done:                      
                    return not terminated, self.env.mpjpe_value, self.env.frame_coverage
                state = next_state

        # If the loop exits without termination, consider it a failure
        return False, self.env.mpjpe_value, self.env.frame_coverage

            
            
    def run_policy(self, epoch: int = 0, dump: bool = False) -> dict:
        """
        Runs the trained policy in the environment.

        Args:
            epoch (int, optional): Current epoch number.
            dump (bool, optional): Flag indicating whether to dump run results.

        Returns:
            dict: Run metrics.
        """
        self.env.start_eval(im_eval = False)
        return super().run_policy(epoch, dump)

    def save_muscle_activation_data(self):
        """
        ä¿å­˜è‚Œè‚‰æ¿€æ´»å’Œç”Ÿç‰©åŠ›å­¦æ•°æ®ï¼Œç”¨äºäººä½“å»ºæ¨¡åˆ†æ
        """
        import pickle
        from datetime import datetime
        
        print("å¼€å§‹ä¿å­˜è‚Œè‚‰æ¿€æ´»æ•°æ®...")
        
        # åˆ›å»ºå¯¼å‡ºç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_dir = f"data/muscle_exports/human_modeling_{timestamp}"
        os.makedirs(export_dir, exist_ok=True)
        
        # æ”¶é›†è‚Œè‚‰æ•°æ®
        try:
            muscle_controls = np.array(self.env.muscle_controls) if hasattr(self.env, 'muscle_controls') and self.env.muscle_controls else np.array([])
            muscle_forces = np.array(self.env.muscle_forces) if hasattr(self.env, 'muscle_forces') and self.env.muscle_forces else np.array([])
            
            print(f"è‚Œè‚‰æ§åˆ¶æ•°æ®å½¢çŠ¶: {muscle_controls.shape}")
            print(f"è‚Œè‚‰åŠ›é‡æ•°æ®å½¢çŠ¶: {muscle_forces.shape}")
            
            if muscle_controls.size > 0:
                # Filter out NaN values for statistics
                valid_controls = muscle_controls[~np.isnan(muscle_controls)]
                if valid_controls.size > 0:
                    print(f"è‚Œè‚‰æ§åˆ¶æ•°å€¼èŒƒå›´: [{np.min(valid_controls):.3f}, {np.max(valid_controls):.3f}]")
                else:
                    print("è‚Œè‚‰æ§åˆ¶æ•°æ®: å…¨éƒ¨ä¸ºNaN")
            
            if muscle_forces.size > 0:
                # Filter out NaN values for statistics
                valid_forces = muscle_forces[~np.isnan(muscle_forces)]
                if valid_forces.size > 0:
                    print(f"è‚Œè‚‰åŠ›é‡æ•°å€¼èŒƒå›´: [{np.min(valid_forces):.2f}, {np.max(valid_forces):.2f}] N")
                else:
                    print("è‚Œè‚‰åŠ›é‡æ•°æ®: å…¨éƒ¨ä¸ºNaN")
            
            # ç»„ç»‡æ•°æ®
            biomech_data = {
                # æ ¸å¿ƒè‚Œè‚‰æ•°æ®
                'muscle_controls': muscle_controls,
                'muscle_forces': muscle_forces,
                
                # è¿åŠ¨å­¦æ•°æ®
                'joint_positions': self.env.joint_pos if hasattr(self.env, 'joint_pos') and self.env.joint_pos else [],
                'joint_velocities': self.env.joint_vel if hasattr(self.env, 'joint_vel') and self.env.joint_vel else [],
                'body_positions': self.env.body_pos if hasattr(self.env, 'body_pos') and self.env.body_pos else [],
                'body_rotations': self.env.body_rot if hasattr(self.env, 'body_rot') and self.env.body_rot else [],
                'body_velocities': self.env.body_vel if hasattr(self.env, 'body_vel') and self.env.body_vel else [],
                
                # å‚è€ƒè¿åŠ¨æ•°æ®
                'reference_positions': self.env.ref_pos if hasattr(self.env, 'ref_pos') and self.env.ref_pos else [],
                'reference_rotations': self.env.ref_rot if hasattr(self.env, 'ref_rot') and self.env.ref_rot else [],
                'reference_velocities': self.env.ref_vel if hasattr(self.env, 'ref_vel') and self.env.ref_vel else [],
                
                # æ¥è§¦å’Œç›¸ä½ä¿¡æ¯
                'feet_contacts': self.env.feet if hasattr(self.env, 'feet') and self.env.feet else [],
                'motion_ids': self.env.motion_id if hasattr(self.env, 'motion_id') and self.env.motion_id else [],
                'policy_outputs': self.env.policy_outputs if hasattr(self.env, 'policy_outputs') and self.env.policy_outputs else [],
                
                # å…ƒæ•°æ®
                'metadata': {
                    'model_name': 'kinesis-moe-imitation',
                    'export_time': timestamp,
                    'num_frames': len(muscle_controls) if muscle_controls.size > 0 else 0,
                    'sampling_frequency': 1/self.env.dt if hasattr(self.env, 'dt') else 30.0,
                    'muscle_count': muscle_controls.shape[1] if muscle_controls.ndim > 1 else 0,
                    'export_purpose': 'human_modeling_for_exoskeleton_analysis',
                }
            }
            
            # ä¿å­˜ä¸»æ•°æ®æ–‡ä»¶
            main_data_file = os.path.join(export_dir, "muscle_activation_data.pkl")
            with open(main_data_file, 'wb') as f:
                pickle.dump(biomech_data, f)
            
            # ä¿å­˜CSVæ–‡ä»¶ç”¨äºå¿«é€ŸæŸ¥çœ‹
            if muscle_controls.size > 0 and muscle_controls.ndim == 2:
                try:
                    import pandas as pd
                    
                    # è‚Œè‚‰æ¿€æ´»æ•°æ®
                    muscle_df = pd.DataFrame(muscle_controls)
                    muscle_df.to_csv(os.path.join(export_dir, "muscle_activations.csv"), index=False)
                    
                    # åŠ›é‡æ•°æ®
                    if muscle_forces.size > 0 and muscle_forces.ndim == 2:
                        force_df = pd.DataFrame(muscle_forces)
                        force_df.to_csv(os.path.join(export_dir, "muscle_forces.csv"), index=False)
                    
                    print(f"âœ… è‚Œè‚‰æ•°æ®å·²ä¿å­˜åˆ°: {export_dir}")
                    print(f"   - ä¸»æ•°æ®æ–‡ä»¶: muscle_activation_data.pkl")
                    print(f"   - è‚Œè‚‰æ¿€æ´»: muscle_activations.csv ({muscle_df.shape})")
                    if muscle_forces.size > 0 and muscle_forces.ndim == 2:
                        print(f"   - è‚Œè‚‰åŠ›é‡: muscle_forces.csv ({force_df.shape})")
                    print(f"   - æ€»å¸§æ•°: {biomech_data['metadata']['num_frames']}")
                    print(f"   - è‚Œè‚‰æ•°é‡: {biomech_data['metadata']['muscle_count']}")
                    
                except ImportError:
                    print("è­¦å‘Š: pandasæœªå®‰è£…ï¼Œä»…ä¿å­˜pickleæ–‡ä»¶")
                    print(f"âœ… è‚Œè‚‰æ•°æ®å·²ä¿å­˜åˆ°: {export_dir}")
                    print(f"   - ä¸»æ•°æ®æ–‡ä»¶: muscle_activation_data.pkl")
            else:
                print("è­¦å‘Š: æœªæ”¶é›†åˆ°æœ‰æ•ˆçš„è‚Œè‚‰æ•°æ®")
            
            # ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š
            self.generate_data_summary(export_dir, biomech_data)
            
            return export_dir
            
        except Exception as e:
            print(f"ä¿å­˜è‚Œè‚‰æ•°æ®æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def generate_data_summary(self, export_dir, data):
        """ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š"""
        
        # è·å–åŠ›é‡æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        force_stats = ""
        if isinstance(data['muscle_forces'], np.ndarray) and data['muscle_forces'].size > 0:
            force_stats = f"""
   - åŠ›é‡èŒƒå›´: [{np.min(data['muscle_forces']):.2f}, {np.max(data['muscle_forces']):.2f}] N
   - å¹³å‡åŠ›é‡: {np.mean(data['muscle_forces']):.2f} N
"""
        else:
            force_stats = "\n   - åŠ›é‡æ•°æ®: æœªæ”¶é›†æˆ–æ ¼å¼å¼‚å¸¸"
        
        summary = f"""
# äººä½“è‚Œè‚‰æ¿€æ´»æ•°æ®å¯¼å‡ºæŠ¥å‘Š

## å¯¼å‡ºä¿¡æ¯
- æ¨¡å‹: kinesis-moe-imitation (MoEæ¶æ„)
- å¯¼å‡ºæ—¶é—´: {data['metadata']['export_time']}
- æ•°æ®å¸§æ•°: {data['metadata']['num_frames']}
- è‚Œè‚‰æ•°é‡: {data['metadata']['muscle_count']}
- é‡‡æ ·é¢‘ç‡: {data['metadata']['sampling_frequency']:.1f} Hz

## æ•°æ®å†…å®¹
1. **è‚Œè‚‰æ¿€æ´»æ•°æ®** (muscle_controls): {len(data['muscle_controls'])} å¸§
   - æ•°å€¼èŒƒå›´: 0-1 (æ¿€æ´»æ°´å¹³)
   - ç”¨é€”: åˆ†æè‚Œè‚‰æ¿€æ´»æ¨¡å¼ï¼Œè¯†åˆ«å¤–éª¨éª¼è¾…åŠ©æ—¶æœº

2. **è‚Œè‚‰åŠ›é‡æ•°æ®** (muscle_forces): {len(data['muscle_forces']) if hasattr(data['muscle_forces'], '__len__') else 'N/A'} å¸§  
   - å•ä½: ç‰›é¡¿ (N){force_stats}
   - ç”¨é€”: è®¡ç®—è‚Œè‚‰è´Ÿè½½ï¼Œè®¾è®¡å¤–éª¨éª¼è¾…åŠ©åŠ›é‡

3. **è¿åŠ¨å­¦æ•°æ®**: å…³èŠ‚ä½ç½®ã€é€Ÿåº¦ï¼Œèº«ä½“å§¿æ€
   - ç”¨é€”: åˆ†æè¿åŠ¨æ¨¡å¼ï¼Œè®¾è®¡å¤–éª¨éª¼æ§åˆ¶ç­–ç•¥

4. **æ­¥æ€æ•°æ®**: è¶³éƒ¨æ¥è§¦ï¼Œè¿åŠ¨ç›¸ä½
   - ç”¨é€”: è¯†åˆ«æ­¥æ€å‘¨æœŸï¼Œä¼˜åŒ–è¾…åŠ©æ—¶æœº

## å¤–éª¨éª¼åˆ†æåº”ç”¨
æ­¤æ•°æ®å¯ç”¨äº:
- è¯†åˆ«éœ€è¦è¾…åŠ©çš„å…³é”®è‚Œç¾¤
- åˆ†æè‚Œè‚‰è´Ÿè½½æ—¶é—´æ¨¡å¼  
- è®¾è®¡å¤–éª¨éª¼è¾…åŠ©ç­–ç•¥
- é‡åŒ–é¢„æœŸçš„å‡è´Ÿæ•ˆæœ

## åç»­æ­¥éª¤
1. è¿è¡Œ analyze_human_modeling.py è¿›è¡Œè¯¦ç»†åˆ†æ
2. åŸºäºåˆ†æç»“æœè®¾è®¡å¤–éª¨éª¼æ§åˆ¶ç®—æ³•
3. ä¸å¤–éª¨éª¼è¾…åŠ©åçš„æ•°æ®è¿›è¡Œå¯¹æ¯”åˆ†æ
"""
        
        summary_path = os.path.join(export_dir, "data_summary.md")
        with open(summary_path, 'w') as f:
            f.write(summary)
        
        print(f"ğŸ“‹ æ•°æ®æ‘˜è¦æŠ¥å‘Šå·²ç”Ÿæˆ: {summary_path}")